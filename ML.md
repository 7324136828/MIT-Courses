Below is an **index** of the papers you listed, **organized by subject** (e.g., Language Models, CNNs, Object Detection, etc.). Each subject heading contains **only** the papers you explicitly included in your curated collection. If you would like more detail on any specific paper (e.g., a summary, key contributions, how it differs from similar works, etc.), just let me know!

---

## 1. Language Models

### 1.1 Encoder-Only Transformers
- **It’s All in The [MASK]** (February 2025)  
- **ModernBERT-Large-Instruct** (December 2024)  
- **DeBERTa v3** (November 2021)  
- **DeBERTa v2** (June 2020)  
- **DeBERTa** (June 2020)  
- **MobileBERT** (April 2020)  
- **FastBERT** (April 2020)  
- **Distil RoBERTa** (October 2019)  
- **Distil BERT** (October 2019)  
- **ALBERT** (September 2019)  
- **Tiny BERT** (September 2019)  
- **Sentence BERT** (August 2019)  
- **RoBERTa** (July 2019)  
- **BERT** (October 2018)

### 1.2 Decoder-Only Transformers
*(Autoregressive / Chat / Instruction-Following LMs)*

- **AceCoder** (February 2025)  
- **o3-mini** (January 2025)  
- **OLMo 2** (January 2025)  
- **Llama 3.3** (December 2024)  
- **Tulu v3** (November 2024)  
- **Aya Expanse** (October 2024)  
- **Llama 3.2** (September 2024)  
- **Llama 3.1-Nemotron-51B** (September 2024)  
- **o1-mini** (September 2024)  
- **o1** (September 2024)  
- **OLMoE** (September 2024)  
- **Hermes 3** (August 2024)  
- **Apple Intelligence Foundation Language Models** (July 2024)  
- **LLM Compiler** (July 2024)  
- **Mistral Large 2** (July 2024)  
- **Llama 3.1 - Multimodal Experiments** (July 2024)  
- **Llama 3.1** (July 2024)  
- **Nemotron-4 340B** (June 2024)  
- **Aya 23** (May 2024)  
- **Codestral 22B** (May 2024)  
- **MAmmoTH 2** (May 2024)  
- **Rho-1** (April 2024)  
- **Command R+** (April 2024)  
- **Llama 3** (April 2024)  
- **Mixtral 8x22B** (April 2024)  
- **Grok 1.5** (March 2024)  
- **Command R** (March 2024)  
- **DBRX** (March 2024)  
- **Nemotron-4 15B** (February 2024)  
- **Mixtral 8x7B** (January 2024)  
- **Tulu v2** (November 2023)  
- **Grok 1** (November 2023)  
- **Llemma** (October 2023)  
- **MAmmoTH** (September 2023)  
- **LLaMA 2 Long** (September 2023)  
- **WizardMath** (August 2023)  
- **Code LLaMA** (August 2023)  
- **Humpback** (August 2023)  
- **Tool LLM** (July 2023)  
- **LLaMA 2** (July 2023)  
- **Tulu** (June 2023)  
- **WizardCoder** (June 2023)  
- **Falcon** (June 2023)  
- **Gorilla** (May 2023)  
- **LIMA** (May 2023)  
- **PaLM 2** (May 2023)  
- **CodeGen 2** (May 2023)  
- **WizardLM** (April 2023)  
- **Pythia** (April 2023)  
- **Bloomberg GPT** (March 2023)  
- **Vicuna** (March 2023)  
- **GPT 4** (March 2023)  
- **Alpaca** (March 2023)  
- **Toolformer** (February 2023)  
- **LLaMA** (February 2023)  
- **ChatGPT** (November 2022)  
- **Galactica** (November 2022)  
- **BLOOM** (November 2022)  
- **OPT** (May 2022)  
- **GPT-NeoX-20B** (April 2022)  
- **PaLM** (April 2022)  
- **CodeGen** (March 2022)  
- **Chinchilla** (March 2022)  
- **Instruct GPT** (March 2022)  
- **LaMDA** (January 2022)  
- **Gopher** (December 2021)  
- **WebGPT** (December 2021)  
- **Codex** (July 2021)  
- **GPT 3** (May 2020)  
- **GPT 2** (February 2019)  
- **GPT** (June 2018)

### 1.3 Small LLMs
- **Mistral Saba** (February 2025)  
- **Mistral Small 3** (January 2025)  
- **Phi-4** (December 2024)  
- **Command R 7B** (December 2024)  
- **Smol LM v2** (November 2024)  
- **Quantized Llama 3.2** (October 2024)  
- **Ministral** (October 2024)  
- **Nemotron-Mini-Hindi** (October 2024)  
- **Mistral Small** (September 2024)  
- **Minitron Approach in Practice** (August 2024)  
- **Phi-3.5** (August 2024)  
- **Smol LM v0.2** (August 2024)  
- **Danube 3** (July 2024)  
- **Minitron** (July 2024)  
- **Phi-3** (July 2024)  
- **Smol LM** (July 2024)  
- **Mathstral** (July 2024)  
- **Orca 3 (Agent Instruct)** (July 2024)  
- **Gemma 2** (June 2024)  
- **Granite Code Models** (May 2024)  
- **Danube 2** (April 2024)  
- **Open ELM** (April 2024)  
- **Phi-3** (April 2024)  
- **CodeGemma** (April 2024)  
- **Gemma** (February 2024)  
- **Orca Math** (February 2024)  
- **Mobile LLM** (February 2024)  
- **OLMo** (February 2024)  
- **Danube** (January 2024)  
- **TinyLlama** (January 2024)  
- **Phi-2** (December 2023)  
- **Orca 2** (November 2023)  
- **Zephyr 7B** (October 2023)  
- **Mistral 7B** (October 2023)  
- **Phi-1.5** (September 2023)  
- **Orca** (June 2023)  
- **Phi-1** (June 2023)

### 1.4 Multimodal LMs
- **Llava-Mini** (January 2025)  
- **Maya** (December 2024)  
- **MAmmoTH-VL** (December 2024)  
- **Smol VLM** (November 2024)  
- **Pixtral Large** (November 2024)  
- **Claude 3.5 Haiku** (October 2024)  
- **Mississippi** (October 2024)  
- **MM-1.5** (September 2024)  
- **Molmo** (September 2024)  
- **NVLM** (September 2024)  
- **Pixtral** (September 2024)  
- **Eagle** (August 2024)  
- **CogVLM2** (August 2024)  
- **Idefics 3** (August 2024)  
- **BLIP-3 (xGen-MM)** (August 2024)  
- **Grok 2** (August 2024)  
- **GPT-4o mini** (July 2024)  
- **Pali Gemma** (July 2024)  
- **Claude 3.5 Sonnet** (June 2024)  
- **Chameleon** (May 2024)  
- **Gemini 1.5 Flash** (May 2024)  
- **GPT-4o** (May 2024)  
- **An Introduction to Vision-Language Modeling** (May 2024)  
- **Phi-3 Vision** (May 2024)  
- **Idefics2** (April 2024)  
- **Grok 1.5 V** (April 2024)  
- **MM-1** (March 2024)  
- **Claude 3** (March 2024)  
- **Gemini 1.5 Pro** (February 2024)  
- **LLaVA 1.6** (January 2024)  
- **MoE-LLaVA** (January 2024)  
- **Gemini 1.0** (December 2023)  
- **CogVLM** (November 2023)  
- **Florence-2** (November 2023)  
- **LLaVA 1.5** (October 2023)  
- **PaLI-3** (October 2023)  
- **GPT-4V** (September 2023)  
- **Idefics** (June 2023)  
- **InstructBLIP** (May 2023)  
- **PaLI-X** (May 2023)  
- **LLaVA 1** (April 2023)  
- **BLIP 2** (January 2023)  
- **PaLI** (September 2022)  
- **Flamingo** (April 2022)  
- **BLIP** (February 2022)  
- **Florence** (November 2021)

### 1.5 LLMs for Math
- **AceMath** (December 2024)  
- **Math Coder 2** (October 2024)  
- **Open Math Instruct 2** (October 2024)  
- **Qwen 2.5 Math** (September 2024)  
- **Qwen 2 Math** (August 2024)  
- **Numina Math** (July 2024)  
- **MuMath Code** (May 2024)  
- **Xwin-Math** (March 2024)  
- **Math Genie** (February 2024)  
- **Math Orca** (February 2024)  
- **Open Math Instruct 1** (February 2024)  
- **DeepSeek Math** (February 2024)  
- **MMIQC** (January 2024)  
- **MuMath** (December 2023)  
- **MAmmoTH** (September 2023)  
- **Wizard Math** (August 2023)

### 1.6 Retrieval and Representation Learning
- **mmE5** (February 2025)  
- **vdr embeddings** (January 2025)  
- **Jina Embeddings v3** (September 2024)  
- **Matryoshka Adaptor** (July 2024)  
- **E5-V** (July 2024)  
- **Jina Reranker v2** (June 2024)  
- **ColPali** (June 2024)  
- **Document Screenshot Embedding** (June 2024)  
- **Nomic Embed Vision v1 / v1.5** (June 2024)  
- **NV Embed** (May 2024)  
- **Gecko** (March 2024)  
- **Jina Reranker** (February 2024)  
- **Jina Bilingual Embeddings** (February 2024)  
- **Nomic Embed Text v1.5** (February 2024)  
- **Nomic Embed Text v1** (February 2024)  
- **E5 Mistral 7B** (December 2023)  
- **SynCLR** (December 2023)  
- **Jina Embeddings v2** (October 2023)  
- **Jina Embeddings v1** (July 2023)  
- **SigLip** (March 2023)  
- **E5** (December 2022)  
- **Matryoshka Representation Learning** (May 2022)  
- **ColBERTv2** (December 2021)  
- **CLIP** (February 2021)  
- **SimCLRv2** (June 2020)  
- **ColBERT** (April 2020)  
- **Dense Passage Retriever** (April 2020)  
- **SimCLR** (February 2020)

### 1.7 LLM Training (Alignment, SFT, RLHF, DPO, etc.)
- **Selective Self-to-Supervised Fine-Tuning (S3FT)** (February 2025)  
- **SelfCite** (February 2025)  
- **SFT Memorizes, RL Generalizes** (January 2025)  
- **Diverse Preference Optimization** (January 2025)  
- **Critique Fine-Tuning** (January 2025)  
- **Multiagent Finetuning** (January 2025)  
- **rStar-Math** (January 2025)  
- **Hyperfitting** (December 2024)  
- **Self-Consistency Preference Optimization** (November 2024)  
- **Thought Preference Optimization** (October 2024)  
- **LongCite** (October 2024)  
- **Constrained Generative Policy Optimization** (Mixture of Judges) (September 2024)  
- **Direct Judgement Preference Optimization** (September 2024)  
- **Self-Taught Evaluators** (August 2024)  
- **Persona Hub** (June 2024)  
- **Instruction Pre-Training** (June 2024)  
- **Magpie** (June 2024)  
- **RLHF Workflow** (May 2024)  
- **WRAP** (March 2024)  
- **Retrieval Augmented Fine Tuning (RAFT)** (March 2024)  
- **V-STaR** (February 2024)  
- **Direct Preference Optimization** (December 2023)  
- **ReST^EM** (December 2023)  
- **Reward rAnked FineTuning (RAFT)** (April 2023)  
- **Reinforced Self-Training (ReST)** (April 2023)  
- **Self Instruct** (December 2022)  
- **Self-Taught Reasoner (STaR)** (May 2022)

### 1.8 Parameter-Efficient Fine-Tuning (PEFT)
- **DoRA** (May 2024)  
- **MoRA** (May 2024)  
- **LoRA+** (February 2024)  
- **VeRA** (October 2023)  
- **LongLoRA** (September 2023)  
- **Delta-LoRA** (September 2023)  
- **LoRA-FA** (August 2023)  
- **QLoRA** (May 2023)  
- **AdaLoRA** (March 2023)  
- **DyLoRA** (October 2022)  
- **LoRA** (July 2021)

---

## 2. Vision Transformers
- **Autoregressive Image Models (AIM)** (January 2024)  
- **Autoregressive Image Models V2** (November 2024)  
- **Shape-Optimized Vision Transformer (SoViT)** (May 2023)  
- **Efficient ViT** (May 2023)  
- **FastVit** (March 2023)  
- **EfficientFormer** (June 2022)  
- **Swin Transformer V2** (April 2022)  
- **Multi-Axis Vision Transformer (MaxViT)** (April 2022)  
- **DINOv2** (April 2022)  
- **Masked AutoEncoder** (November 2021)  
- **MobileViT** (October 2021)  
- **BEiT** (June 2021)  
- **DINO** (April 2021)  
- **LeViT** (April 2021)  
- **CvT** (March 2021)  
- **Swin Transformer** (March 2021)  
- **DeiT** (December 2020)  
- **Vision Transformer** (October 2020)

---

## 3. Convolutional Neural Networks (CNNs)
- **Mobile Net V4** (April 2024)  
- **Efficient Net V2** (April 2024)  
- **ConvNeXt V2** (January 2023)  
- **ConvNeXt** (January 2022)  
- **Conv Mixer** (January 2022)  
- **NF Net** (February 2021)  
- **Efficient Net** (May 2019)  
- **Mobile Net V3** (May 2019)  
- **Mobile Net V2** (January 2018)  
- **Mobile Net V1** (April 2017)  
- **Res Next** (November 2016)  
- **Xception** (October 2016)  
- **Dense Net** (August 2016)  
- **Inception Net v4 / Inception ResNet** (February 2016)  
- **Res Net** (December 2015)  
- **Inception Net v2 / Inception Net v3** (December 2015)  
- **Inception Net** (September 2014)  
- **VGG** (September 2014)  
- **Alex Net** (September 2012)  
- **Lenet** (December 1998)

---

## 4. Object Detection

- **Segment Anything Model (SAM) 2** (July 2024)  
- **Segment Anything Model (SAM)** (April 2023)  
- **OWL ViT** (May 2022)  
- **DETR** (May 2020)  
- **Focal Loss** (August 2017) *(often cited with RetinaNet)*  
- **Feature Pyramid Network** (December 2016)  
- **SSD** (December 2015)

### 4.1 RCNNs
- **Cascade RCNN** (December 2017)  
- **Mask RCNN** (March 2017)  
- **Faster RCNN** (June 2015)  
- **Fast RCNN** (April 2015)  
- **RCNN** (November 2013)

---

## 5. Document Understanding

- **Spreadsheet LLM** (July 2024)  
- **DocLLM** (January 2024)  
- **LMDX** (September 2023)  
- **Nougat** (August 2023)  
- **GeoLayoutLM** (April 2023)  
- **UDoP** (December 2022)  
- **DePlot** (December 2022)  
- **Matcha** (December 2022)  
- **Pix2Struct** (October 2022)  
- **DiT** (March 2022)  
- **Donut** (November 2021)  
- **Layout Parser** (March 2021)  
- **SPADE** (May 2020)  
- **Table Net** (January 2020)

### 5.1 Layout-Aware LMs
- **ERNIE Layout** (October 2022)  
- **Layout LM V3** (April 2022)  
- **LiLT** (February 2022)  
- **BROS** (August 2021)  
- **Doc Former** (June 2021)  
- **Structural LM** (May 2021)  
- **Layout LM v2** (December 2020)  
- **LamBERT** (February 2020)  
- **Layout LM** (December 2019)

---

## 6. GANs

- **Cycle GAN** (March 2017)  
- **Wasserstein Generative Adversarial Networks** (January 2017)  
- **Improved GAN** (June 2016)  
- **Deep Convolutional Generative Adversarial Networks** (November 2015)  
- **Conditional Generative Adversarial Networks** (November 2014)  
- **Generative Adversarial Networks** (June 2014)

---

## 7. Tabular Data

- **Feature Tokenizer Transformer** (June 2021)  
- **Tabular ResNet** (June 2021)  
- **Tab Transformer** (December 2020)  
- **Deep and Cross Network** (August 2017)  
- **Wide and Deep Learning** (June 2016)  
- **Entity Embeddings** (April 2016)

---

## 8. Datasets

- **Red Pajama V2** (November 2024)  
- **Red Pajama V1** (November 2024)  
- **Smol Talk** (November 2024)  
- **PixMo** (September 2024)  
- **Docmatix** (July 2024)  
- **Cosmopedia v2** (July 2024)  
- **Fine Web** (May 2024)  
- **RewardBench** (March 2024)  
- **Cosmopedia** (March 2024)  
- **WebSight** (March 2024)  
- **Aya Dataset** (February 2024)  
- **Dolma** (January 2024)  
- **Obelics** (June 2023)

---

## 9. Neural Network Layers

### 9.1 Normalization Layers
- **Batch Channel Normalisation**  
- **Weight Standardisation**  
- **Group Normalisation**  
- **Instance Normalisation**  
- **Layer Normalisation**  
- **Batch Normalisation**

### 9.2 Attention Layers
- **Grouped Query Attention**  
- **Multi Query Attention**  
- **Sliding Window Attention**  
- **Causal Attention**  
- **Cross Attention**  
- **Multi Head Attention**  
- **Scaled Dot Product Attention**

### 9.3 Recurrent Layers
- **GRU**  
- **LSTM**  
- **Simple Recurrent Neural Network**

### 9.4 Convolution Layers
- **Convolution Transpose**  
- **Separable Convolution**  
- **Depthwise Convolution**  
- **Pointwise Convolution**  
- **Convolution Layer**

---

## 10. Autoencoders

- **Masked Auto Encoders**  
- **Variational Auto Encoders**  
- **Denoising Auto Encoders**  
- **Sequence to Sequence Auto Encoders**  
- **Convolutional Auto Encoders**  
- **Contractive Auto Encoders**  
- **K Sparse Auto Encoders**  
- **Sparse Auto Encoders**  
- **Auto Encoders** (classic)

---

## 11. Miscellaneous Studies

- **OmniParser V2** (February 2025)  
- **Reader LM v2** (December 2024)  
- **Multi-LLM Text Summarization** (December 2024)  
- **Shiksha** (December 2024)  
- **Open Scholar** (December 2024)  
- **LearnLM** (December 2024)  
- **NuExtract 1.5** (October 2024)  
- **GSM-Symbolic** (October 2024)  
- **DataGemma** (September 2024)  
- **Reader-LM** (September 2024)  
- **OmniParser** (August 2024)  
- **Shield Gemma** (July 2024)  
- **Gemma APS** (June 2024)  
- **CriticGPT** (June 2024)  
- **Proofread** (June 2024)  
- **NuExtract** (June 2024)  
- **Monte Carlo Tree Self-refine** (June 2024)  
- **LearnLM Tutor** (May 2024)  
- **PromptWizard** (May 2024)  
- **Prometheus 2** (May 2024)  
- **LLMLingua2** (March 2024)  
- **NuNER** (February 2024)  
- **STORM** (February 2024)  
- **An In-depth Look at Gemini's Language Abilities** (December 2023)  
- **Prometheus** (October 2023)  
- **LongLLMLingua** (October 2023)  
- **LLMLingua** (October 2023)  
- **DSPy** (October 2023)  
- **RAGAS** (September 2023)  
- **Multiagent Debate** (May 2023)  
- **Scaling Data-Constrained Language Models** (May 2023)  
- **Are Emergent Abilities of Large Language Models a Mirage?** (April 2023)  
- **ColD Fusion** (December 2022)  
- **TLDR** (April 2020)

---

## 12. Surveys
- **A Survey of Small Language Models** (October 2024)  
- **Small Language Models: Survey, Measurements, and Insights** (September 2024)  
- **What is the Role of Small Models in the LLM Era** (September 2024)  
- **The Prompt Report: A Systematic Survey of Prompting Techniques** (June 2024)  
- **Best Practices and Lessons Learned on Synthetic Data** (April 2024)

---

## 13. Journeys
*(High-level “mind-map” or “timeline”-style overviews)*

- **Low Rank Adaptors** (LoRA, DyLoRA, AdaLoRA, QLoRA, etc.)  
- **Vision Transformers** (ViT, DeiT, Swin, etc.)  
- **Encoder Only Transformers** (BERT to DeBERTa v3)  
- **Decoder Only Transformers** (GPT series, LLaMA, Code LLaMA, etc.)  
- **Small LLMs** (Orca, Mistral, Phi, Gemma, etc.)  
- **Multi Task Language Models**  
- **Layout Aware Transformers**  
- **Retrieval and Representation Learning**  
- **LLM Evaluation**  
- **Convolutional Neural Networks**  
- **Object Detection (RCNN Family)**  
- **Document Information Processing**  

---

## 14. Literature Reviews
- **Convolutional Neural Networks** (covers LeNet → EfficientNet)  
- **Layout Transformers** (LayoutLM, LamBERT, etc.)  
- **Region Based Convolutional Neural Networks** (R-CNN, Fast R-CNN, etc.)  
- **Tabular Deep Learning** (Entity Embeddings, Wide & Deep, etc.)  
- **Generative Adversarial Networks** (GAN → CycleGAN)  
- **Parameter Efficient FineTuning** (LoRA → DoRA)  
- **Convolution Layers**  
- **Recurrent Layers**  
- **Attention Layers**  
- **Normalization Layers**  
- **Auto Encoders**  
- **LLMs for Maths**  

---

## 15. Reading Lists
- **Language Models: Encoder Only / Decoder Only**  
- **LLMs for Code**  
- **Small LLMs**  
- **GPT Models**  
- **LLaMA Models**  
- **Gemini / Gemma Models**  
- **Wizard Models**  
- **Orca Series**  
- **BLIP Series**  
- **LLM Lingua Series**  
- **Multi-Task Language Models**  
- **Layout Aware Transformers**  
- **Retrieval and Representation Learning**  
- **Vision Transformers**  
- **Multi-Modal Transformers**  
- **LLM Evaluation**  
- **Convolutional Neural Networks**  
- **Object Detection (RCNN)**  
- **Document Information Processing**  

---

### How to Get More Details

- **Want a PDF / original link?** Many of these papers are on [arXiv.org](https://arxiv.org/) or were published at major ML conferences (NeurIPS, ICML, ICLR, ACL, etc.).  
- **Need a deeper summary?** Let me know which paper you want to explore. I can provide a more detailed breakdown of its contributions, methods, experiments, and impact.  
- **Comparisons**: If you want side-by-side comparisons—for example, how **LoRA** differs from **AdaLoRA**—just ask!

Feel free to specify any **title or set of keywords** you want to focus on, and I can help you drill down further into these references.
